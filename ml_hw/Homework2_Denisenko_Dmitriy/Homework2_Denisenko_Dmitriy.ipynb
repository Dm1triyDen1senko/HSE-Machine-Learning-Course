{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7vl14vY17Xx"
   },
   "source": [
    "# Домашнее задание №2\n",
    "\n",
    "**Максимальная оценка за работу `min(X, 10)`, где X - суммарный балл за hw2 из 12 возможных.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTmabsBR17X3"
   },
   "source": [
    "## Часть 1. ML workflow (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eN7XrCe217X4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4bq1HnB17X7"
   },
   "source": [
    "### Загрузим данные для работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HtFOlGCU17X8",
    "outputId": "a6edf2e5-204d-4586-fa22-a9f0b762e6c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = pd.read_csv(\"winequality-red.csv\")\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHgnBqr717X-"
   },
   "source": [
    "Будем решать задачу регрессии: необходимо предсказать качество вина на основе его характеристик\n",
    "\n",
    "### Шаг 1.  (**0.2 балла**)\n",
    "Создайте матрицу X объект-признак и целевой вектор y (\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OfN1V4Of17X-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599, 11), (1599,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = wine_data.drop(columns=['quality'])\n",
    "y = wine_data['quality']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QYaYYUh17X_"
   },
   "source": [
    "### Шаг 2. (**0.2 балла**)\n",
    "Разбейте данные на train и test (доля тестовых данных - 30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3MOH47U517YA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1119, 11), (480, 11), (1119,), (480,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fORyaCO17YB"
   },
   "source": [
    "### Шаг 3. (**0.2 балла**)\n",
    "Обучите линейную регрессию на тренировочных данных и сделайте предсказания на train и на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GViwO1Fy17YB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания на тренировочноых данных: [6.35882698 5.9774259  5.66887262 5.67281951 5.38838989]\n",
      "Предсказания на тестовых данных: [5.35676319 5.09071476 5.62553757 5.44886088 5.74478368]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(f'Предсказания на тренировочных данных: {y_train_pred[:5]}')\n",
    "print(f'Предсказания на тестовых данных: {y_test_pred[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEQur8eP17YC"
   },
   "source": [
    "### Шаг 4. (**0.4 балла**)\n",
    "Выведите на экран ошибку MSE на train и на test, затем выведите на экран ошибку r2 на train и test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "jKBk7fvn17YD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE-train: 0.42\n",
      "MSE-test: 0.41\n",
      "R^2-train: 0.36\n",
      "R^2-test: 0.35\n"
     ]
    }
   ],
   "source": [
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'MSE-train: {mse_train:.2f}')\n",
    "print(f'MSE-test: {mse_test:.2f}')\n",
    "print(f'R^2-train: {r2_train:.2f}')\n",
    "print(f'R^2-test: {r2_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejd9S4Q_17YD"
   },
   "source": [
    "### Шаг 5. (**0.5 балла**)\n",
    "Вычислите среднее качество (r2) модели на кросс-валидации с k=5 фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Abn-QTyM17YE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество (R^2) модели на кросс-валидации с k=5 фолдами: 0.29\n"
     ]
    }
   ],
   "source": [
    "cv_r2 = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "mean_r2 = cv_r2.mean()\n",
    "\n",
    "print(f'Среднее качество (R^2) модели на кросс-валидации с k=5 фолдами: {mean_r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vniRLzAM17YE"
   },
   "source": [
    "### Шаг 6.  (**0.5 балла**)\n",
    "Теперь примените линейную регрессию с L1-регуляризацией (Lasso) для данной задачи. Объявите модель и подберите параметр регуляризации alpha по сетке. Ищите alpha в диапазоне (0.1, 1.1) с шагом 0.1.\n",
    "\n",
    "Осуществите подбор параметра alpha по тренировочным данным (Xtrain, ytrain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9simWseX17YF"
   },
   "outputs": [],
   "source": [
    "alpha_variants = np.arange(0.1, 1.1, 0.1)\n",
    "\n",
    "lasso = Lasso()\n",
    "param_grid = {'alpha': alpha_variants}\n",
    "\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_r2_train = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KZC5uOQ17YG"
   },
   "source": [
    "### Шаг 7.  (**0.5 балла**)\n",
    "Выведите наилучший алгоритм и наилучшее качество по результатам подбора alpha (best_estimator_ и best_score_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "HZBo6bZY17YG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее значение альфы: Lasso(alpha=0.1)\n",
      "Значение R^2 при наилучшей альфе на тренировочной выборке: 0.24\n"
     ]
    }
   ],
   "source": [
    "best_estimator = grid_search.best_estimator_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Наилучшее значение альфы: {best_estimator}')\n",
    "print(f'Значение R^2 при наилучшей альфе на тренировочной выборке: {best_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJghumt117YH"
   },
   "source": [
    "### Шаг 8.  (**0.5 балла**)\n",
    "\n",
    "С помощью найденного best_estimator_ сделайте предсказание на тестовых данных и выведите на экран r2-score на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "BBMQvQs817YH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение R^2-score на тесте: 0.21\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_lasso = best_estimator.predict(X_test)\n",
    "\n",
    "r2_test_lasso = r2_score(y_test, y_test_pred_lasso)\n",
    "\n",
    "print(f'Значение R^2-score на тесте: {r2_test_lasso:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sKZz1LK17YI"
   },
   "source": [
    "### Шаг 9.  (**0.5 балла**)\n",
    "\n",
    "Попробуем улучшить качество модели за счет добавления полиномиальных признаков. Создайте pipeline, состоящий из добавления полиномиальных признаков степени 2, а затем применения линейной регрессии.\n",
    "\n",
    "Затем вычислите r2-score этой модели на кросс валидации с пятью фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "xcgzVSsM17YI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение R^2: 0.23\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "cv_r2_poly_scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "mean_cv_r2_poly = cv_r2_poly_scores.mean()\n",
    "\n",
    "mean_cv_r2_poly\n",
    "\n",
    "print(f'Значение R^2: {mean_cv_r2_poly:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHdHiMQ_17YJ"
   },
   "source": [
    "### Шаг 10.  (**0.5 балла**)\n",
    "Обучите модель (pipeline) на тренировочных данных и сделайте предсказания для train и test, затем выведите на экран r2-score и MSE на тренировочных и на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "jBjwIal-17YK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение R^2 для тренировочных данных: 0.45\n",
      "Значение R^2 для тестовых данных: 0.35\n",
      "\n",
      "Значение MSE для тренировочных данных: 0.36\n",
      "Значение MSE для тестовых данных: 0.41\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_poly = pipeline.predict(X_train)\n",
    "y_test_pred_poly = pipeline.predict(X_test)\n",
    "\n",
    "r2_train_poly = r2_score(y_train, y_train_pred_poly)\n",
    "mse_train_poly = mean_squared_error(y_train, y_train_pred_poly)\n",
    "\n",
    "r2_test_poly = r2_score(y_test, y_test_pred_poly)\n",
    "mse_test_poly = mean_squared_error(y_test, y_test_pred_poly)\n",
    "\n",
    "r2_train_poly, mse_train_poly, r2_test_poly, mse_test_poly\n",
    "\n",
    "print(f'Значение R^2 для тренировочных данных: {r2_train_poly:.2f}')\n",
    "print(f'Значение R^2 для тестовых данных: {r2_test_poly:.2f}')\n",
    "print()\n",
    "print(f'Значение MSE для тренировочных данных: {mse_train_poly:.2f}')\n",
    "print(f'Значение MSE для тестовых данных: {mse_test_poly:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RYZ62Uo17YK"
   },
   "source": [
    "### Сделайте выводы. Для этого ответьте на вопросы: (**1 балл**)\n",
    "\n",
    "1) Хорошее ли качество показала исходная модель (линейная регрессия без регуляризации)? Является ли эта модель переобученной?\n",
    "\n",
    "2) Помогла ли L1-регуляризация улучшить качество модели?\n",
    "\n",
    "3) Помогло ли добавление полиномов второй степени улучшить качество модели? Как добавление новых признаков повлияло на переобучение?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLr_PQQt17YL"
   },
   "source": [
    "**Ответы:**\n",
    "\n",
    "1. Исходная модель показала значение R^2 около 0.36 на тренировочной выборке и 0.35 на тестовой. Получается, что объясняется треть дисперсии целевой переменной - в принципе это умеренное качество для модели линейной регрессии. Исходная модель не является переобученной - R^2 для тренировочной и тестовой выборок достаточно близки.\n",
    "\n",
    "2. L1-регуляризация с alpha^* = 0.1 уменьшила R^2 на тестовой выборке (до 0.21) и обеспечила сжатие некоторых коэффициентов признаков к нулю. Это могло бы улучшить качество модели, если бы признаки были избыточными или имели высокую корреляцию. Однако в данном случае - линейная модель уже была достаточно простой и устойчивой к переобучению.\n",
    "\n",
    "3. Полиномиальные признаки степени 2 увеличили выразительную мощность модели и привели к увеличению R^2 на тренировочной выборке до 0.451, но на тестовой выборке качество не изменилось. Значит, добавление полиномиальных признаков повысило способность модели объяснять дисперсию в обучающей выборке, но не дало существенного улучшения на тестовых данных. Это указывает на переобучение - полиномиальные признаки привели к увеличению сложности модели, что, по-видимому, привело к запоминанию тренировочных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o-lDGMS17YL"
   },
   "source": [
    "### *Попытайтесь улучшить модель (добейтесь наилучшего качества) - можно использовать любые методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euSZN9aj17YM"
   },
   "source": [
    "При улучшении качества r2 на 0.1-0.2 +1 балл, при большем улучшении +2 балла (дополнительно к 5 баллам за основную часть)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение R^2 при обучении с помощью случайного леса: 0.448, MSE (test): 0.350\n",
      "Результат на тестовой выборке стал лучше! - delta R^2 = 0.10\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('random_forest', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'random_forest__n_estimators': [100, 150],\n",
    "    'random_forest__max_depth': [10, None],\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, scoring='r2')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "y_test_pred_rf = best_rf_model.predict(X_test)\n",
    "r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "\n",
    "print(f'Значение R^2 при обучении с помощью случайного леса: {r2_rf:.3f}, MSE (test): {mse_rf:.3f}')\n",
    "print(f'Результат на тестовой выборке стал лучше! - delta R^2 = {(r2_rf - r2_test_poly):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq9VJY3117YN"
   },
   "source": [
    "## Часть 2. Target encoding (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q08IEgtr17YO"
   },
   "source": [
    "В этом части домашнего задания вы будете работать с выборкой `1C`. Вам нужно посчитать счетчики для `item_id` четырьмя способами:\n",
    "\n",
    "    1) При помощи KFold схемы;  \n",
    "    2) При помощи Leave-one-out схемы;\n",
    "    3) При помощи smoothing схемы;\n",
    "    4) При помощи expanding mean схемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AZ8ZwvP17YQ"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "X7oNha7017YS",
    "outputId": "3d61e9bf-5e85-438b-813a-a1626363265e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935844</th>\n",
       "      <td>10.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935845</th>\n",
       "      <td>09.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935846</th>\n",
       "      <td>14.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7459</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935847</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7440</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935848</th>\n",
       "      <td>03.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2935849 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  date_block_num  shop_id  item_id  item_price  target\n",
       "0        02.01.2013               0       59    22154      999.00     1.0\n",
       "1        03.01.2013               0       25     2552      899.00     1.0\n",
       "2        05.01.2013               0       25     2552      899.00    -1.0\n",
       "3        06.01.2013               0       25     2554     1709.05     1.0\n",
       "4        15.01.2013               0       25     2555     1099.00     1.0\n",
       "...             ...             ...      ...      ...         ...     ...\n",
       "2935844  10.10.2015              33       25     7409      299.00     1.0\n",
       "2935845  09.10.2015              33       25     7460      299.00     1.0\n",
       "2935846  14.10.2015              33       25     7459      349.00     1.0\n",
       "2935847  22.10.2015              33       25     7440      299.00     1.0\n",
       "2935848  03.10.2015              33       25     7460      299.00     1.0\n",
       "\n",
       "[2935849 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('sales_train.csv.gz')\n",
    "sales.columns = ['date', 'date_block_num', 'shop_id', 'item_id', 'item_price', 'target']\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "pf2RAhgG17YV"
   },
   "outputs": [],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = []\n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'target':'sum'})\n",
    "\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKxPEUME17YX"
   },
   "source": [
    "### Mean encodings без регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAKXDv2P17YY"
   },
   "source": [
    "После проделанной технической работы, мы готовы посчитать счетчики для переменной `item_id`.\n",
    "\n",
    "Ниже приведены две реализации подсчета счетчиков без регуляризации. Можно использовать данный код в качестве стартовой точки для реализации различных техник регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDJIXqPJ17YZ"
   },
   "source": [
    "#### Способ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nP0txxgu17YZ",
    "outputId": "71675772-09fc-4c64-cbc5-28376a5966fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48303869886216966\n"
     ]
    }
   ],
   "source": [
    "# Calculate a mapping: {item_id: target_mean}\n",
    "item_id_target_mean = all_data.groupby('item_id').target.mean()\n",
    "\n",
    "# In our non-regularized case we just *map* the computed means to the `item_id`'s\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mc7TQh6V17Yb"
   },
   "source": [
    "#### Способ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Ujgcz3um17Yc",
    "outputId": "e218ca20-126f-4806-a18f-89fa33b8eb6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48303869886216966\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "     Differently to `.target.mean()` function `transform`\n",
    "   will return a dataframe with an index like in `all_data`.\n",
    "   Basically this single line of code is equivalent to the first two lines from of Method 1.\n",
    "'''\n",
    "all_data['item_target_enc'] = all_data.groupby('item_id')['target'].transform('mean')\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRCBHEWe17Yd"
   },
   "source": [
    "###  KFold схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRXNZsdL17Ye"
   },
   "source": [
    "Необходимо реализовать Kfold схему с пятью фолдами. Используйте KFold(5) из sklearn.model_selection.\n",
    "\n",
    "1. Разбейте данные на 5 фолдов при помощи `sklearn.model_selection.KFold` с параметром `shuffle=False`.\n",
    "2. Проитерируйтесь по фолдам: используйте 4 обучающих фолда для подсчета средних значений таргета по `item_id` и заполните этими значениями валидационный фолд на каждой итерации.\n",
    "\n",
    "Обратите внимание на **Способ 1** из примера. В частности, изучите, как работают функции map и pd.Series.map. Они довольно полезны во многих ситуациях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "cN4oOO-d17Yf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция: 0.41\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "all_data['item_target_enc_kfold'] = np.nan\n",
    "\n",
    "for train_index, val_index in kf.split(all_data):\n",
    "\n",
    "    train_data, val_data = all_data.iloc[train_index], all_data.iloc[val_index]\n",
    "\n",
    "    item_id_target_mean = train_data.groupby('item_id')['target'].mean()\n",
    "    \n",
    "    all_data.loc[val_index, 'item_target_enc_kfold'] = val_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "all_data['item_target_enc_kfold'].fillna(all_data['target'].mean(), inplace=True)\n",
    "\n",
    "encoded_feature = all_data['item_target_enc_kfold'].values\n",
    "correlation = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "\n",
    "print(f'Корреляция: {correlation:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYVw71Yj17aG"
   },
   "source": [
    "### Leave-one-out схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ9BuEDM17aG"
   },
   "source": [
    "Необходимо реализовать leave-one-out схему . Учтите, если вы запустите код из первого задания, задав количество фолдов такое же как размер выборки, то вы, вероятно, получите правильный ответ, но ждать будете очень-очень долго.\n",
    "\n",
    "Для более быстрой реализации подсчета среднего таргета на всех объектах, кроме одного, вы можете:\n",
    "\n",
    "1. Вычислить суммарный таргет по всем объектам.\n",
    "2. Вычесть таргет конкретного объекта и разделить результат на `n_objects - 1`.\n",
    "\n",
    "Заметим, что пункт `1.` следует сделать для всех объектов. Также заметим, что пункт `2.` может быть реализован без циклов `for`.\n",
    "\n",
    "Здесь может оказаться полезной функция .transform из **Способа 2** из примера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "P4-NTaGL17aH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция: 0.48\n"
     ]
    }
   ],
   "source": [
    "item_counts = all_data.groupby('item_id')['target'].transform('count')\n",
    "\n",
    "item_sums = all_data.groupby('item_id')['target'].transform('sum')\n",
    "\n",
    "all_data['item_target_enc_loo'] = (item_sums - all_data['target']) / (item_counts - 1)\n",
    "\n",
    "all_data['item_target_enc_loo'].fillna(all_data['target'].mean(), inplace=True)\n",
    "\n",
    "encoded_feature = all_data['item_target_enc_loo'].values\n",
    "correlation = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "\n",
    "print(f'Корреляция: {correlation:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8Dzq8xW17aI"
   },
   "source": [
    "### Smoothing (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neuv-Vu317aI"
   },
   "source": [
    "Необходимо реализовать smoothing с $\\alpha = 100$. Используйте формулу:\n",
    "\n",
    "$\\frac{mean(target) \\cdot nrows + globalmean \\cdot \\alpha }{nrows + \\alpha}$,\n",
    "\n",
    "где $globalmean=0.3343$. Заметим, что `nrows` - это количество объектов, принадлежащих конкретной категории, а не количество строк в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "pwjuyAnv17aI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция: 0.48\n"
     ]
    }
   ],
   "source": [
    "global_mean = 0.3343\n",
    "alpha = 100\n",
    "\n",
    "item_means = all_data.groupby('item_id')['target'].transform('mean')\n",
    "\n",
    "item_counts = all_data.groupby('item_id')['target'].transform('count')\n",
    "\n",
    "all_data['item_target_enc_smoothing'] = (item_means * item_counts + global_mean * alpha) / (item_counts + alpha)\n",
    "\n",
    "all_data['item_target_enc_smoothing'].fillna(global_mean, inplace=True)\n",
    "\n",
    "encoded_feature = all_data['item_target_enc_smoothing'].values\n",
    "correlation = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "\n",
    "print(f'Корреляция: {correlation:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4exEAIF17aJ"
   },
   "source": [
    "### Expanding mean схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inIMt53z17aJ"
   },
   "source": [
    "Необходимо реализовать *expanding mean* схему. Ее суть заключается в том, чтобы пройти по отсортированному в определенном порядке датасету (датасет сортируется в самом начале задания) и для подсчета счетчика для строки $m$ использовать строки от $0$ до $m-1$. Вам будет необходимо воспользоваться pandas функциями [`cumsum`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.cumsum.html) и [`cumcount`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.cumcount.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "A1F4FW9X17aJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция: 0.50\n"
     ]
    }
   ],
   "source": [
    "cumulative_sum = all_data.groupby('item_id')['target'].cumsum() - all_data['target']\n",
    "\n",
    "cumulative_count = all_data.groupby('item_id').cumcount()\n",
    "\n",
    "all_data['item_target_enc_expanding'] = cumulative_sum / cumulative_count\n",
    "\n",
    "all_data['item_target_enc_expanding'].fillna(all_data['target'].mean(), inplace=True)\n",
    "\n",
    "encoded_feature = all_data['item_target_enc_expanding'].values\n",
    "correlation = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "\n",
    "print(f'Корреляция: {correlation:.2f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
